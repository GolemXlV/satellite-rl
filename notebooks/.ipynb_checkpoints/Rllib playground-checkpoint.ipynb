{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-27 15:21:04,271\tWARNING services.py:597 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-01-27 15:21:04,273\tINFO resource_spec.py:216 -- Starting Ray with 4.98 GiB memory available for workers and up to 40.0 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-01-27 15:21:04,559\tWARNING services.py:1354 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 27412729856 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.100',\n",
       " 'redis_address': '192.168.1.100:54631',\n",
       " 'object_store_address': '/tmp/ray/session_2020-01-27_15-21-04_247423_5349/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-01-27_15-21-04_247423_5349/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2020-01-27_15-21-04_247423_5349'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init(num_cpus=12, num_gpus=1, memory=1024 * 1024 * 1024 * 5, object_store_memory=1024 * 1024 * 1024 * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.registry import register_env\n",
    "import gym\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return gym.make(\"satellite_gym:SatelliteEnv-v1\")\n",
    "\n",
    "# env = SatelliteEnv(df, sat_id=sat_id)\n",
    "register_env(\"SatelliteEnv-v1\", lambda x: env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.rllib.agents.impala as impala\n",
    "from ray.tune.logger import pretty_print\n",
    "from pathlib import Path\n",
    "\n",
    "def on_train_result(info):\n",
    "    result = info[\"result\"]\n",
    "    if result[\"episode_reward_mean\"] > 45:\n",
    "        phase = 2\n",
    "    elif result[\"episode_reward_mean\"] > 22:\n",
    "        phase = 1\n",
    "    else:\n",
    "        phase = 0\n",
    "    trainer = info[\"trainer\"]\n",
    "    trainer.workers.foreach_worker(\n",
    "        lambda ev: ev.foreach_env(\n",
    "            lambda env: env.set_phase(phase)))\n",
    "    \n",
    "    \n",
    "config = impala.DEFAULT_CONFIG.copy()\n",
    "config['model']['use_lstm'] = True\n",
    "config[\"model\"][\"vf_share_layers\"] = True\n",
    "config[\"num_workers\"] = 10\n",
    "config[\"num_gpus\"] = 1\n",
    "config[\"seed\"] = 0\n",
    "config[\"eager\"] = False\n",
    "config[\"lr\"] = 1e-05\n",
    "config[\"num_envs_per_worker\"] = 10\n",
    "# config[\"num_gpus_per_worker\"] = .1\n",
    "config[\"sample_batch_size\"] = 4000\n",
    "config[\"train_batch_size\"] = 80000\n",
    "config[\"callbacks\"] = { \"on_train_result\": on_train_result }\n",
    "\n",
    "trainer = impala.ImpalaTrainer(config=config, env=\"satellite_gym:SatelliteEnv-v1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.restore(\"/home/golemxiv/ray_results/IMPALA-04gmoje1lu/checkpoint_201/checkpoint-201\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.config['lr'] = 1e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(401):\n",
    "    # Perform one iteration of training the policy with PPO\n",
    "    result = trainer.train()\n",
    "    print(pretty_print(result))\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        checkpoint = trainer.save()\n",
    "        print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_policy().export_model('trained_model_v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# obs = np.zeros((256), dtype=np.float32)\n",
    "obs = np.squeeze(env.df.head(256).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from satellite_gym.envs.satellite_env.satellite_env import TRAIN_COLUMNS, TEST_COLUMNS\n",
    "trainer.get_policy().compute_single_action(obs=np.squeeze(env.df[TRAIN_COLUMNS].head(1).values), state=trainer.get_policy().get_initial_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_value = env.df[['Vx', 'Vy', 'Vz']].values\n",
    "\n",
    "policy = trainer.get_policy()\n",
    "state = policy.get_initial_state()\n",
    "predicted_value = np.empty((1, 3,))\n",
    "for i in range(len(true_value)):\n",
    "#     if len(predicted_value) == 1:\n",
    "#         predicted_value = np.array([env.df[['Vx_sim', 'Vy_sim', 'Vz_sim']].loc[i].values])\n",
    "    val = policy.compute_single_action(np.squeeze(env.df[TRAIN_COLUMNS].loc[i].values), state=state)\n",
    "    state = val[1]\n",
    "    predicted_value = np.append(predicted_value, [val[0][3:]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D #<-- Note the capitalization! \n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig) #<-- Note the difference from your original code...\n",
    "ax.scatter(xs=true_value[:,:1], ys=true_value[:,1:2], zs=true_value[:,2:3], marker='o')\n",
    "ax.scatter(xs=predicted_value[:,:1], ys=predicted_value[:,1:2], zs=predicted_value[:,2:3], marker='^')\n",
    "ax.view_init(elev=10., azim=20)\n",
    "plt.show()\n",
    "# for ii in range(0,360,1):\n",
    "#         ax.view_init(elev=10., azim=ii)\n",
    "#         fig.savefig(\"movie/movie%d.png\" % ii)\n",
    "\n",
    "\n",
    "#ax + by + cz + d = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(x=true_value[:,:1], y=true_value[:,1:2], z=true_value[:,2:3], mode='markers')])\n",
    "fig.write_image(\"figure.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:idao]",
   "language": "python",
   "name": "conda-env-idao-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
